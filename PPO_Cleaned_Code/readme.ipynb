{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ddebc95",
   "metadata": {},
   "source": [
    "<div>\n",
    "<br><h1  style=\"color:grey;\" >\n",
    "<a id=\"dqn_ddpg_link\"></a> DQN , DDPG, PPO A2C Implementation from scratch</h1></br>\n",
    "<a style=\"color:navyblue;font-size:15px;\" href ='#table_of_content_link'>Go Back to Table of Content</a>\n",
    "\n",
    "<ul id=\"ul_1\">\n",
    "    <b><I>\n",
    "    <li>Section 1: Overview </li>\n",
    "    <li>Section 2. Result</li>\n",
    "    <li>Section 3. Flowchart</li>\n",
    "    </b></I>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3> 1.  Overview </h3>\n",
    "\n",
    "<div id=div_style> \n",
    "  PPO implemented and tested on OpenAI gym Bipedal Walker Environment.The algorithm is implemnted from scratch using TensorFlow, Numpy and Python.\n",
    "This is an implementation of the following paper by <a href=\"https://openai.com/\">OpenAI</a><br>\n",
    "<b><i>Proximal Policy Optimization Algorithms</b></i> <a href=\"https://arxiv.org/abs/1707.06347\">arxiv link</a><br><br>\n",
    "Implemented by : Irfan Mohammad Al Hasib <br>\n",
    "E-Mail : irfanhasib.me@gmail.com <br>\n",
    "Website : <a href=\"https://irfanhasib0.github.io\">https://irfanhasib0.github.io</a><br>\n",
    "LinkedIN : <a href=\"https://www.linkedin.com/in/irfanhasib/\">https://www.linkedin.com/in/irfanhasib/</a><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<h3> 2. Results </h3>\n",
    "\n",
    "Results PPO on Bipedal Walker\n",
    "         \n",
    "<img src=\"img/bipedal_ppo.jpg\" align=\"left\"\n",
    "     title=\"(Open Image in new tab for full resolution)\" width=\"100%\" />\n",
    "\n",
    "<img src=\"img/bipedal_ppo.gif\" align=\"left\"\n",
    "     title=\"(Open Image in new tab for full resolution)\" width=\"45%\" />\n",
    "<img src=\"img/lunar_ppo.gif\" align=\"left\"\n",
    "     title=\"(Open Image in new tab for full resolution)\" width=\"50%\" /><br>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<h3> Codes </h3>\n",
    "<ul>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/PPO_Cleaned_Code/5.1_PPO_Bipedal_Walker-revised-clr>  PPO for Bipedal Walker - Notebook (Cleaned and Organized code) </a></li>\n",
    "\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/5.2_PPO_Lunar_Lander.ipynb>  PPO for Lunar Lander - Notebook (Raw Code) </a></li>\n",
    "</ul>\n",
    "    \n",
    "<div>\n",
    "<h3> 3. Detailed Flow Chart for DQN and DDPG : (Please Zoom or Open in New tab for proper resolution) </h3>\n",
    "\n",
    "    \n",
    "<img src=\"img/ppo_algo_1.jpg\" align=\"left\"\n",
    "     title=\"Open Image in new tab for good resolution\" width=\"100%\" height=\"200%\">\n",
    "\n",
    "<img src=\"img/ppo_algo_2.jpg\" align=\"left\"\n",
    "     title=\"Open Image in new tab for good resolution\" width=\"100%\" height=\"200%\">\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa58c7",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h3>  Links for other implementations : </h3>\n",
    "<ul>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/1.0_Multi_Arm_Bandit.ipynb>  Multi Arm Bandit - Notebook </a></li>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/2.1_Value_Iteration.ipynb>   Value Iteration - Notebook  </a></li>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/3.0_DQN_Mountain_Car.ipynb>  DQN for Mountain Car - Notebook  </a></li>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/4.0_DDPG_Pendulum-mod.ipynb> DDPG for Pendulum - Notebook</a></li>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/5.1_PPO_Bipedal_Walker-mod.ipynb>  PPO for Bipedal Walker - Notebook</a></li>\n",
    "<li><a style=\"color:navyblue;font-size:15px;\" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/5.2_PPO_Lunar_Lander.ipynb>  PPO for Lunar Lander - Notebook </a></li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
