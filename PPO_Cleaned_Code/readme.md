<div>
<br><h1  style="color:grey;" >
<a id="dqn_ddpg_link"></a> DQN , DDPG, PPO A2C Implementation from scratch</h1></br>
<a style="color:navyblue;font-size:15px;" href ='#table_of_content_link'>Go Back to Table of Content</a>

<ul id="ul_1">
    <b><I>
    <li>Section 1: Overview </li>
    <li>Section 2. Result</li>
    <li>Section 3. Flowchart</li>
    </b></I>
</ul>


<h3> 1.  Overview </h3>

<div id=div_style> 
  PPO implemented and tested on OpenAI gym Bipedal Walker Environment.The algorithm is implemnted from scratch using TensorFlow, Numpy and Python.
This is an implementation of the following paper by <a href="https://openai.com/">OpenAI</a><br>
<b><i>Proximal Policy Optimization Algorithms</b></i> <a href="https://arxiv.org/abs/1707.06347">arxiv link</a><br><br>
Implemented by : Irfan Mohammad Al Hasib <br>
E-Mail : irfanhasib.me@gmail.com <br>
Website : <a href="https://irfanhasib0.github.io">https://irfanhasib0.github.io</a><br>
LinkedIN : <a href="https://www.linkedin.com/in/irfanhasib/">https://www.linkedin.com/in/irfanhasib/</a><br>

</div>

<div>
<h3> 2. Results </h3>

Results PPO on Bipedal Walker
         
<img src="img/bipedal_ppo.jpg" align="left"
     title="(Open Image in new tab for full resolution)" width="100%" />

<img src="img/bipedal_ppo.gif" align="left"
     title="(Open Image in new tab for full resolution)" width="45%" />
<img src="img/lunar_ppo.gif" align="left"
     title="(Open Image in new tab for full resolution)" width="50%" /><br>
    
</div>

<h3> Codes </h3>
<ul>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/PPO_Cleaned_Code/5.1_PPO_Bipedal_Walker-revised-clr>  PPO for Bipedal Walker - Notebook (Cleaned and Organized code) </a></li>

<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/5.2_PPO_Lunar_Lander.ipynb>  PPO for Lunar Lander - Notebook (Raw Code) </a></li>
</ul>
    
<div>
<h3> 3. Detailed Flow Chart for DQN and DDPG : (Please Zoom or Open in New tab for proper resolution) </h3>

    
<img src="img/ppo_algo_1.jpg" align="left"
     title="Open Image in new tab for good resolution" width="100%" height="200%">

<img src="img/ppo_algo_2.jpg" align="left"
     title="Open Image in new tab for good resolution" width="100%" height="200%">
     
</div>

<div>
<h3>  Links for other implementations : </h3>
<ul>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/1.0_Multi_Arm_Bandit.ipynb>  Multi Arm Bandit - Notebook </a></li>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/2.1_Value_Iteration.ipynb>   Value Iteration - Notebook  </a></li>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/3.0_DQN_Mountain_Car.ipynb>  DQN for Mountain Car - Notebook  </a></li>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/4.0_DDPG_Pendulum-mod.ipynb> DDPG for Pendulum - Notebook</a></li>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/5.1_PPO_Bipedal_Walker-mod.ipynb>  PPO for Bipedal Walker - Notebook</a></li>
<li><a style="color:navyblue;font-size:15px;" href= https://github.com/irfanhasib0/RL-Algorithms/blob/master/5.2_PPO_Lunar_Lander.ipynb>  PPO for Lunar Lander - Notebook </a></li>
</ul>
</div>
