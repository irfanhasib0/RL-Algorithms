{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import tensorflow as tf\n",
    "import json, sys, os\n",
    "from os import path\n",
    "import random\n",
    "from collections import deque\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "#env_to_use = 'Pendulum-v0'\n",
    "env_to_use = 'CarRacing-v0'\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "h1_actor = 8\n",
    "h2_actor = 8\n",
    "h3_actor = 8\n",
    "h1_critic = 8\n",
    "h2_critic = 8\n",
    "h3_critic = 8\n",
    "gamma = 0.99\n",
    "lr_actor = 1e-3\n",
    "lr_critic = 1e-3\n",
    "lr_decay = 1\n",
    "l2_reg_actor = 1e-6\n",
    "l2_reg_critic = 1e-6\n",
    "dropout_actor = 0\n",
    "dropout_critic = 0\n",
    "num_episodes = 100\n",
    "max_steps_ep = 3000\n",
    "tau = 1e-2\n",
    "train_every = 1\n",
    "replay_memory_capacity = int(1e5)\n",
    "minibatch_size = 64#1024\n",
    "initial_noise_scale = 0.1\n",
    "noise_decay = 0.99\n",
    "exploration_mu = 0.0\n",
    "exploration_theta = 0.15\n",
    "exploration_sigma = 0.2\n",
    "\n",
    "# game parameters\n",
    "env = gym.make(env_to_use)\n",
    "state_dim = env.observation_space.shape\n",
    "action_dim = np.prod(np.array(env.action_space.shape))\n",
    "\n",
    "# set seeds to 0\n",
    "env.seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.high - env.action_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = deque(maxlen=replay_memory_capacity)\n",
    "\n",
    "def add_to_memory(experience):\n",
    "    replay_memory.append(experience)\n",
    "\n",
    "def sample_from_memory(minibatch_size):\n",
    "    return random.sample(replay_memory, minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\irfan\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "class ANN():\n",
    "    tf.reset_default_graph()\n",
    "    state_ph  =  tf.placeholder(dtype=tf.float32, shape=[None,state_dim[0],state_dim[1],state_dim[2]])\n",
    "    action_ph = tf.placeholder(dtype=tf.float32, shape=[None,action_dim])\n",
    "    reward_ph = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "    next_state_ph = tf.placeholder(dtype=tf.float32, shape=[None,state_dim[0],state_dim[1],state_dim[2]])\n",
    "    is_not_terminal_ph = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "    \n",
    "\n",
    "    \n",
    "    episodes = tf.Variable(0.0, trainable=False, name='episodes')\n",
    "    episode_inc_op = episodes.assign_add(1)\n",
    "    \n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('actor'):\n",
    "            self.actor_net_value = ANN.generate_actor_network(self,trainable = True, reuse = False)\n",
    "              \n",
    "        \n",
    "        with tf.variable_scope('slow_target_actor', reuse=False):\n",
    "            self.target_actor_net_value = tf.stop_gradient(ANN.generate_actor_network(self,trainable = False, reuse = False))\n",
    "\n",
    "        with tf.variable_scope('critic') as scope:\n",
    "            self.critic_net_value = ANN.generate_critic_network(self,trainable = True, reuse = False)\n",
    "            self.q_value_for_actor_net = ANN.generate_critic_network(self,trainable = True, reuse = True,mode=2)\n",
    "\n",
    "        \n",
    "        with tf.variable_scope('slow_target_critic', reuse=False):\n",
    "            self.target_critic_net_value = tf.stop_gradient(ANN.generate_critic_network(self,trainable = False, reuse = False,mode=3))\n",
    "        \n",
    "        \n",
    "        self.actor_net_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='actor')\n",
    "        self.target_actor_net_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='slow_target_actor')\n",
    "        self.critic_net_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='critic')\n",
    "        self.target_critic_net_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='slow_target_critic')\n",
    "\n",
    "        \n",
    "    def predict_graph(self):\n",
    "        return self.actor_net_value\n",
    "    def generate_actor_network(self,trainable, reuse):\n",
    "        layer1_out = tf.layers.conv2d(ANN.state_ph, filters=16, kernel_size=[8, 8],\n",
    "                                      strides=[4, 4], padding='same', activation=tf.nn.relu, data_format='channels_last', name='actor_layer1_out')\n",
    "        layer2_out = tf.layers.conv2d(layer1_out, filters=32, kernel_size=[4, 4],\n",
    "                                      strides=[2, 2], padding='same', activation=tf.nn.relu, data_format='channels_last', name='actor_layer2_out')\n",
    "        layer3_out = tf.layers.dense(tf.layers.flatten(layer2_out), 256, activation=tf.nn.relu, name='actor_layer3_out')\n",
    "        #output = tf.layers.dense(layer3_out, action_size, activation=None, name='output')\n",
    "        #hidden = tf.layers.dense(ANN.state_ph, h1_actor, activation = tf.nn.relu, trainable = trainable, name = 'dense', reuse = reuse)\n",
    "        #hidden_2 = tf.layers.dense(hidden, h2_actor, activation = tf.nn.relu, trainable = trainable, name = 'dense_1', reuse = reuse)\n",
    "        #hidden_3 = tf.layers.dense(hidden_2, h3_actor, activation = tf.nn.relu, trainable = trainable, name = 'dense_2', reuse = reuse)\n",
    "        actions_unscaled = tf.layers.dense(layer3_out, action_dim, trainable = trainable, name = 'dense_3', reuse = reuse)\n",
    "        actions = env.action_space.low + tf.nn.sigmoid(actions_unscaled)*(env.action_space.high - env.action_space.low) # bound the actions to the valid range\n",
    "        return actions_unscaled\n",
    "\n",
    "   \n",
    "    \n",
    "    def generate_critic_network(self,trainable, reuse,mode=1):\n",
    "        layer1_out = tf.layers.conv2d(ANN.state_ph, filters=16, kernel_size=[8, 8],\n",
    "                                      strides=[4, 4], padding='same', activation=tf.nn.relu, data_format='channels_last', name='critic_layer1_out',reuse = reuse)\n",
    "        layer2_out = tf.layers.conv2d(layer1_out, filters=32, kernel_size=[4, 4],\n",
    "                                      strides=[2, 2], padding='same', activation=tf.nn.relu, data_format='channels_last', name='critic_layer2_out',reuse = reuse)\n",
    "        layer2_flat=tf.layers.flatten(layer2_out)\n",
    "        if mode==1:\n",
    "            state_action = tf.concat([layer2_flat, ANN.action_ph], axis=1)\n",
    "        if mode==2:\n",
    "            state_action = tf.concat([layer2_flat,self.actor_net_value], axis=1)\n",
    "        if mode==3:\n",
    "            state_action = tf.concat([layer2_flat,self.target_actor_net_value], axis=1)\n",
    "        layer3_out = tf.layers.dense(state_action, 256, activation=tf.nn.relu, name='critic_layer3_out',reuse = reuse)\n",
    "        #hidden = tf.layers.dense(state_action, h1_critic, activation = tf.nn.relu, trainable = trainable, name = 'dense', reuse = reuse)\n",
    "        #hidden_2 = tf.layers.dense(hidden, h2_critic, activation = tf.nn.relu, trainable = trainable, name = 'dense_1', reuse = reuse)\n",
    "        #hidden_3 = tf.layers.dense(hidden_2, h3_critic, activation = tf.nn.relu, trainable = trainable, name = 'dense_2', reuse = reuse)\n",
    "        q_values = tf.layers.dense(layer3_out, 1, trainable = trainable, name = 'dense_3', reuse = reuse)\n",
    "        return q_values\n",
    "    def train_graph(self):\n",
    "        updated_q_values = tf.expand_dims(ANN.reward_ph, 1) + tf.expand_dims(ANN.is_not_terminal_ph, 1) * gamma * self.target_critic_net_value\n",
    "        td_errors = updated_q_values - self.critic_net_value\n",
    "\n",
    "\n",
    "        critic_loss = tf.reduce_mean(tf.square(td_errors))\n",
    "        for var in self.critic_net_vars:\n",
    "            if not 'bias' in var.name:\n",
    "                critic_loss += l2_reg_critic * 0.5 * tf.nn.l2_loss(var)\n",
    "\n",
    "\n",
    "        critic_train_op = tf.train.AdamOptimizer(lr_critic).minimize(critic_loss)\n",
    "        actor_loss = -1*tf.reduce_mean(self.q_value_for_actor_net)\n",
    "        for var in self.actor_net_vars:\n",
    "            if not 'bias' in var.name:\n",
    "                actor_loss += l2_reg_actor * 0.5 * tf.nn.l2_loss(var)\n",
    "\n",
    "        actor_train_op = tf.train.AdamOptimizer(lr_actor).minimize(actor_loss, var_list=self.actor_net_vars)\n",
    "        return actor_train_op,critic_train_op\n",
    "        \n",
    "    def update_wts_graph(self):\n",
    "            update_slow_target_ops = []\n",
    "            for i, target_actor_var in enumerate(self.target_actor_net_vars):\n",
    "                update_slow_target_actor_op = target_actor_var.assign(tau*self.actor_net_vars[i]+(1-tau)*target_actor_var)\n",
    "                update_slow_target_ops.append(update_slow_target_actor_op)\n",
    "\n",
    "            for i, slow_target_var in enumerate(self.target_critic_net_vars):\n",
    "                update_slow_target_critic_op = slow_target_var.assign(tau*self.critic_net_vars[i]+(1-tau)*slow_target_var)\n",
    "                update_slow_target_ops.append(update_slow_target_critic_op)\n",
    "\n",
    "            update_slow_targets_op = tf.group(*update_slow_target_ops, name='update_slow_targets')\n",
    "            return update_slow_targets_op \n",
    "    def load_weights(self,_actor_net_vars,_critic_net_vars):\n",
    "            update_wts_ops = []\n",
    "            for i, actor_var in enumerate(self.actor_net_vars):\n",
    "                update_actor_op = actor_var.assign(_actor_net_vars[i])\n",
    "                update_wts_ops.append(update_actor_op)\n",
    "\n",
    "            for i, critic_var in enumerate(self.critic_net_vars):\n",
    "                update_critic_op = critic_var.assign(_critic_net_vars[i])\n",
    "                update_wts_ops.append(update_critic_op)\n",
    "\n",
    "            update_wts_ops = tf.group(*update_wts_ops, name='update_wts_ops')\n",
    "            return update_wts_ops \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-6a2a19ee7061>:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\irfan\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-6a2a19ee7061>:49: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-6a2a19ee7061>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "Model=ANN()\n",
    "actor_net_value=Model.predict_graph()\n",
    "actor_train_op,critic_train_op=Model.train_graph()\n",
    "update_wts_op=Model.update_wts_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# initialize session\n",
    "#sess = tf.Session()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1143..1442 -> 299-tiles track\n",
      "Episode  0, Reward: -76.510, Steps: 1000, noise:   0.200\n",
      "Track generation: 1087..1369 -> 282-tiles track\n",
      "Episode  1, Reward: -92.883, Steps: 1000, noise:   0.198\n",
      "Track generation: 964..1212 -> 248-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "Episode  2, Reward: -86.532, Steps: 1000, noise:   0.196\n",
      "Track generation: 1283..1608 -> 325-tiles track\n",
      "Episode  3, Reward: -87.654, Steps: 1000, noise:   0.194\n",
      "Track generation: 1217..1526 -> 309-tiles track\n",
      "Episode  4, Reward: -83.766, Steps: 1000, noise:   0.192\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "Episode  5, Reward: -81.949, Steps: 1000, noise:   0.190\n",
      "Track generation: 1198..1501 -> 303-tiles track\n",
      "Episode  6, Reward: -83.444, Steps: 1000, noise:   0.188\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Episode  7, Reward: -82.935, Steps: 1000, noise:   0.186\n",
      "Track generation: 957..1205 -> 248-tiles track\n",
      "Episode  8, Reward: -79.757, Steps: 1000, noise:   0.185\n",
      "Track generation: 1181..1480 -> 299-tiles track\n",
      "Episode  9, Reward: -93.289, Steps: 1000, noise:   0.183\n",
      "Track generation: 979..1234 -> 255-tiles track\n",
      "Episode 10, Reward: -92.126, Steps: 1000, noise:   0.181\n",
      "Track generation: 1320..1654 -> 334-tiles track\n",
      "Episode 11, Reward: -84.985, Steps: 1000, noise:   0.179\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Episode 12, Reward: -81.481, Steps: 1000, noise:   0.177\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Episode 13, Reward: -92.593, Steps: 1000, noise:   0.176\n",
      "Track generation: 1207..1513 -> 306-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\gym\\envs\\box2d\\car_dynamics.py:158: RuntimeWarning: invalid value encountered in sign\n",
      "  dir = -np.sign(w.omega)\n",
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\gym\\envs\\box2d\\car_dynamics.py:130: RuntimeWarning: invalid value encountered in sign\n",
      "  dir = np.sign(w.steer - w.joint.angle)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 14, Reward: 941.800, Steps: 582, noise:   0.174\n",
      "Track generation: 1106..1396 -> 290-tiles track\n",
      "Episode 15, Reward: 999.800, Steps: 2, noise:   0.172\n",
      "Track generation: 1296..1628 -> 332-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1047..1319 -> 272-tiles track\n",
      "Episode 16, Reward: 999.800, Steps: 2, noise:   0.170\n",
      "Track generation: 1245..1560 -> 315-tiles track\n",
      "Episode 17, Reward: 999.800, Steps: 2, noise:   0.169\n",
      "Track generation: 1232..1544 -> 312-tiles track\n",
      "Episode 18, Reward: 999.800, Steps: 2, noise:   0.167\n",
      "Track generation: 1120..1408 -> 288-tiles track\n",
      "Episode 19, Reward: 999.800, Steps: 2, noise:   0.165\n",
      "Track generation: 1225..1536 -> 311-tiles track\n",
      "Episode 20, Reward: 999.800, Steps: 2, noise:   0.164\n",
      "Track generation: 1077..1357 -> 280-tiles track\n",
      "Episode 21, Reward: 999.800, Steps: 2, noise:   0.162\n",
      "Track generation: 1322..1664 -> 342-tiles track\n",
      "Episode 22, Reward: 999.800, Steps: 2, noise:   0.160\n",
      "Track generation: 1035..1297 -> 262-tiles track\n",
      "Episode 23, Reward: 999.800, Steps: 2, noise:   0.159\n",
      "Track generation: 1297..1626 -> 329-tiles track\n",
      "Episode 24, Reward: 999.800, Steps: 2, noise:   0.157\n",
      "Track generation: 1294..1621 -> 327-tiles track\n",
      "Episode 25, Reward: 999.800, Steps: 2, noise:   0.156\n",
      "Track generation: 1055..1331 -> 276-tiles track\n",
      "Episode 26, Reward: 999.800, Steps: 2, noise:   0.154\n",
      "Track generation: 1202..1507 -> 305-tiles track\n",
      "Episode 27, Reward: 999.800, Steps: 2, noise:   0.152\n",
      "Track generation: 863..1087 -> 224-tiles track\n",
      "Episode 28, Reward: 999.800, Steps: 2, noise:   0.151\n",
      "Track generation: 1227..1538 -> 311-tiles track\n",
      "Episode 29, Reward: 999.800, Steps: 2, noise:   0.149\n",
      "Track generation: 1317..1652 -> 335-tiles track\n",
      "Episode 30, Reward: 999.800, Steps: 2, noise:   0.148\n",
      "Track generation: 1115..1402 -> 287-tiles track\n",
      "Episode 31, Reward: 999.800, Steps: 2, noise:   0.146\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Episode 32, Reward: 999.800, Steps: 2, noise:   0.145\n",
      "Track generation: 1056..1324 -> 268-tiles track\n",
      "Episode 33, Reward: 999.800, Steps: 2, noise:   0.144\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "Episode 34, Reward: 999.800, Steps: 2, noise:   0.142\n",
      "Track generation: 1260..1579 -> 319-tiles track\n",
      "Episode 35, Reward: 999.800, Steps: 2, noise:   0.141\n",
      "Track generation: 1100..1379 -> 279-tiles track\n",
      "Episode 36, Reward: 999.800, Steps: 2, noise:   0.139\n",
      "Track generation: 1185..1485 -> 300-tiles track\n",
      "Episode 37, Reward: 999.800, Steps: 2, noise:   0.138\n",
      "Track generation: 1034..1296 -> 262-tiles track\n",
      "Episode 38, Reward: 999.800, Steps: 2, noise:   0.137\n",
      "Track generation: 1076..1352 -> 276-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1132..1419 -> 287-tiles track\n",
      "Episode 39, Reward: 999.800, Steps: 2, noise:   0.135\n",
      "Track generation: 1292..1619 -> 327-tiles track\n",
      "Episode 40, Reward: 999.800, Steps: 2, noise:   0.134\n",
      "Track generation: 1275..1598 -> 323-tiles track\n",
      "Episode 41, Reward: 999.800, Steps: 2, noise:   0.132\n",
      "Track generation: 1056..1324 -> 268-tiles track\n",
      "Episode 42, Reward: 999.800, Steps: 2, noise:   0.131\n",
      "Track generation: 1092..1377 -> 285-tiles track\n",
      "Episode 43, Reward: 999.800, Steps: 2, noise:   0.130\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "Episode 44, Reward: 999.800, Steps: 2, noise:   0.129\n",
      "Track generation: 1104..1384 -> 280-tiles track\n",
      "Episode 45, Reward: 999.800, Steps: 2, noise:   0.127\n",
      "Track generation: 1131..1430 -> 299-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "Episode 46, Reward: 999.800, Steps: 2, noise:   0.126\n",
      "Track generation: 1155..1448 -> 293-tiles track\n",
      "Episode 47, Reward: 999.800, Steps: 2, noise:   0.125\n",
      "Track generation: 1317..1650 -> 333-tiles track\n",
      "Episode 48, Reward: 999.800, Steps: 2, noise:   0.123\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Episode 49, Reward: 999.800, Steps: 2, noise:   0.122\n",
      "Track generation: 1170..1467 -> 297-tiles track\n",
      "Episode 50, Reward: 999.800, Steps: 2, noise:   0.121\n",
      "Track generation: 1022..1282 -> 260-tiles track\n",
      "Episode 51, Reward: 999.800, Steps: 2, noise:   0.120\n",
      "Track generation: 1230..1542 -> 312-tiles track\n",
      "Episode 52, Reward: 999.800, Steps: 2, noise:   0.119\n",
      "Track generation: 1018..1278 -> 260-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1126..1412 -> 286-tiles track\n",
      "Episode 53, Reward: 999.800, Steps: 2, noise:   0.117\n",
      "Track generation: 1251..1568 -> 317-tiles track\n",
      "Episode 54, Reward: 999.800, Steps: 2, noise:   0.116\n",
      "Track generation: 1202..1507 -> 305-tiles track\n",
      "Episode 55, Reward: 999.800, Steps: 2, noise:   0.115\n",
      "Track generation: 1265..1592 -> 327-tiles track\n",
      "Episode 56, Reward: 999.800, Steps: 2, noise:   0.114\n",
      "Track generation: 1049..1315 -> 266-tiles track\n",
      "Episode 57, Reward: 999.800, Steps: 2, noise:   0.113\n",
      "Track generation: 1345..1685 -> 340-tiles track\n",
      "Episode 58, Reward: 999.800, Steps: 2, noise:   0.112\n",
      "Track generation: 929..1167 -> 238-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1059..1328 -> 269-tiles track\n",
      "Episode 59, Reward: 999.800, Steps: 2, noise:   0.111\n",
      "Track generation: 981..1236 -> 255-tiles track\n",
      "Episode 60, Reward: 999.800, Steps: 2, noise:   0.109\n",
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "Episode 61, Reward: 999.800, Steps: 2, noise:   0.108\n",
      "Track generation: 1062..1332 -> 270-tiles track\n",
      "Episode 62, Reward: 999.800, Steps: 2, noise:   0.107\n",
      "Track generation: 1148..1439 -> 291-tiles track\n",
      "Episode 63, Reward: 999.800, Steps: 2, noise:   0.106\n",
      "Track generation: 983..1235 -> 252-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1106..1387 -> 281-tiles track\n",
      "Episode 64, Reward: 999.800, Steps: 2, noise:   0.105\n",
      "Track generation: 1068..1339 -> 271-tiles track\n",
      "Episode 65, Reward: 999.800, Steps: 2, noise:   0.104\n",
      "Track generation: 1285..1611 -> 326-tiles track\n",
      "Episode 66, Reward: 999.800, Steps: 2, noise:   0.103\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "Episode 67, Reward: 999.800, Steps: 2, noise:   0.102\n",
      "Track generation: 1095..1373 -> 278-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1209..1515 -> 306-tiles track\n",
      "Episode 68, Reward: 999.800, Steps: 2, noise:   0.101\n",
      "Track generation: 1167..1463 -> 296-tiles track\n",
      "Episode 69, Reward: 999.800, Steps: 2, noise:   0.100\n",
      "Track generation: 1215..1523 -> 308-tiles track\n",
      "Episode 70, Reward: 999.800, Steps: 2, noise:   0.099\n",
      "Track generation: 1292..1619 -> 327-tiles track\n",
      "Episode 71, Reward: 999.800, Steps: 2, noise:   0.098\n",
      "Track generation: 1099..1378 -> 279-tiles track\n",
      "Episode 72, Reward: 999.800, Steps: 2, noise:   0.097\n",
      "Track generation: 1179..1478 -> 299-tiles track\n",
      "Episode 73, Reward: 999.800, Steps: 2, noise:   0.096\n",
      "Track generation: 1107..1388 -> 281-tiles track\n",
      "Episode 74, Reward: 999.800, Steps: 2, noise:   0.095\n",
      "Track generation: 1209..1519 -> 310-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1233..1544 -> 311-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1234..1555 -> 321-tiles track\n",
      "Episode 75, Reward: 999.800, Steps: 2, noise:   0.094\n",
      "Track generation: 1232..1553 -> 321-tiles track\n",
      "Episode 76, Reward: 999.800, Steps: 2, noise:   0.093\n",
      "Track generation: 1214..1522 -> 308-tiles track\n",
      "Episode 77, Reward: 999.800, Steps: 2, noise:   0.092\n",
      "Track generation: 1151..1450 -> 299-tiles track\n",
      "Episode 78, Reward: 999.800, Steps: 2, noise:   0.091\n",
      "Track generation: 1213..1529 -> 316-tiles track\n",
      "Episode 79, Reward: 999.800, Steps: 2, noise:   0.090\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "Episode 80, Reward: 999.800, Steps: 2, noise:   0.090\n",
      "Track generation: 1040..1304 -> 264-tiles track\n",
      "Episode 81, Reward: 999.800, Steps: 2, noise:   0.089\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "Episode 82, Reward: 999.800, Steps: 2, noise:   0.088\n",
      "Track generation: 1121..1408 -> 287-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1048..1319 -> 271-tiles track\n",
      "Episode 83, Reward: 999.800, Steps: 2, noise:   0.087\n",
      "Track generation: 1224..1534 -> 310-tiles track\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 84, Reward: 999.800, Steps: 2, noise:   0.086\n",
      "Track generation: 1140..1429 -> 289-tiles track\n",
      "Episode 85, Reward: 999.800, Steps: 2, noise:   0.085\n",
      "Track generation: 1114..1400 -> 286-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      "Episode 86, Reward: 999.800, Steps: 2, noise:   0.084\n",
      "Track generation: 1045..1313 -> 268-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1131..1418 -> 287-tiles track\n",
      "Episode 87, Reward: 999.800, Steps: 2, noise:   0.083\n",
      "Track generation: 1122..1412 -> 290-tiles track\n",
      "Episode 88, Reward: 999.800, Steps: 2, noise:   0.083\n",
      "Track generation: 1239..1553 -> 314-tiles track\n",
      "Episode 89, Reward: 999.800, Steps: 2, noise:   0.082\n",
      "Track generation: 1022..1283 -> 261-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1123..1408 -> 285-tiles track\n",
      "Episode 90, Reward: 999.800, Steps: 2, noise:   0.081\n",
      "Track generation: 1158..1462 -> 304-tiles track\n",
      "Episode 91, Reward: 999.800, Steps: 2, noise:   0.080\n",
      "Track generation: 1313..1645 -> 332-tiles track\n",
      "Episode 92, Reward: 999.800, Steps: 2, noise:   0.079\n",
      "Track generation: 1000..1254 -> 254-tiles track\n",
      "Episode 93, Reward: 999.800, Steps: 2, noise:   0.079\n",
      "Track generation: 1259..1578 -> 319-tiles track\n",
      "Episode 94, Reward: 999.800, Steps: 2, noise:   0.078\n",
      "Track generation: 1316..1655 -> 339-tiles track\n",
      "Episode 95, Reward: 999.800, Steps: 2, noise:   0.077\n",
      "Track generation: 1086..1367 -> 281-tiles track\n",
      "Episode 96, Reward: 999.800, Steps: 2, noise:   0.076\n",
      "Track generation: 988..1238 -> 250-tiles track\n",
      "Episode 97, Reward: 999.800, Steps: 2, noise:   0.075\n",
      "Track generation: 1072..1344 -> 272-tiles track\n",
      "Episode 98, Reward: 999.800, Steps: 2, noise:   0.075\n",
      "Track generation: 1152..1444 -> 292-tiles track\n",
      "Episode 99, Reward: 999.800, Steps: 2, noise:   0.074\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "## Training\n",
    "\n",
    "total_steps = 0\n",
    "log_rewards=[]\n",
    "for ep in range(num_episodes):\n",
    "\n",
    "    total_reward = 0\n",
    "    steps_in_ep = 0\n",
    "\n",
    "    \n",
    "    noise_process = np.zeros(action_dim)\n",
    "    noise_scale = (initial_noise_scale * noise_decay**ep) * (env.action_space.high - env.action_space.low)\n",
    "\n",
    "    \n",
    "    observation = env.reset()\n",
    "    for t in range(max_steps_ep):\n",
    "        obs=observation/255.0\n",
    "        action_for_state, = sess.run(actor_net_value,\n",
    "            feed_dict = {Model.state_ph:obs[None] })\n",
    "\n",
    "        \n",
    "        noise_process = exploration_theta*(exploration_mu - noise_process) + exploration_sigma*np.random.randn(action_dim)\n",
    "        action_for_state += noise_scale*noise_process\n",
    "\n",
    "       \n",
    "        next_observation, reward, done, _info = env.step(action_for_state)\n",
    "        total_reward += reward\n",
    "\n",
    "        add_to_memory((obs , action_for_state, reward, next_observation, \n",
    "            0.0 if done else 1.0))\n",
    "        \n",
    "        if total_steps%train_every == 0 and len(replay_memory) >= minibatch_size:\n",
    "\n",
    "           \n",
    "            minibatch = sample_from_memory(minibatch_size)\n",
    "\n",
    "            _, _ = sess.run([critic_train_op, actor_train_op], \n",
    "                feed_dict = {\n",
    "                    Model.state_ph: np.asarray([elem[0] for elem in minibatch]),\n",
    "                    Model.action_ph: np.asarray([elem[1] for elem in minibatch]),\n",
    "                    Model.reward_ph: np.asarray([elem[2] for elem in minibatch]),\n",
    "                    Model.next_state_ph: np.asarray([elem[3] for elem in minibatch]),\n",
    "                    Model.is_not_terminal_ph: np.asarray([elem[4] for elem in minibatch]),\n",
    "                    })\n",
    "\n",
    "\n",
    "            _ = sess.run(update_wts_op)\n",
    "\n",
    "        observation = next_observation\n",
    "        total_steps += 1\n",
    "        steps_in_ep += 1\n",
    "        \n",
    "        if done: \n",
    "            \n",
    "            _ = sess.run(Model.episode_inc_op)\n",
    "            break\n",
    "    log_rewards.append([ep,total_reward])\n",
    "    print('Episode %2i, Reward: %7.3f, Steps: %i, noise: %7.3f'%(ep,total_reward,steps_in_ep, noise_scale[0]))\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge tqdm\n",
    "#conda install -c conda-forge ipywidgets\n",
    "#conda install -c conda-forge nodejs#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm.write('Episode %2i, Reward: %7.3f, Steps: %i, noise: %7.3f'%(ep,total_reward,steps_in_ep, noise_scale[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_net_var,critic_net_vars):\n",
    "            import pickle\n",
    "            f=open('net_wts','wb')\n",
    "            pickle.dump([actor_wts,critic_wts],f)\n",
    "            f.close() \n",
    "def load_weights(Model,sess):\n",
    "            import pickle\n",
    "            f=open('net_wts','rb')\n",
    "            [actor_wts,critic_wts]=pickle.load(f)\n",
    "            f.close()\n",
    "            sess.run(Model.load_weights(actor_wts,critic_wts))\n",
    "            return actor_wts,critic_wts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True\n",
    "if save==True:\n",
    "    actor_wts=sess.run(Model.actor_net_vars)\n",
    "    critic_wts=sess.run(Model.critic_net_vars)\n",
    "    save_weights(actor_wts,critic_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load=False\n",
    "if load==True:\n",
    "    load_weights(Model,sess)\n",
    "    a_wts=sess.run(Model.actor_net_vars)\n",
    "    c_wts=sess.run(Model.critic_net_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1143..1442 -> 299-tiles track\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n",
      "[1.0292315         nan 0.26590514]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "env=gym.make(env_to_use)\n",
    "env.seed(0)\n",
    "obs=env.reset()\n",
    "\n",
    "#os.mkdir(env_to_use+'Test')\n",
    "#os.mkdir(env_to_use+'Test/img/')\n",
    "for i in range(1000):\n",
    "    img=obs/255.0\n",
    "    _action, = sess.run(actor_net_value, \n",
    "                    feed_dict = {Model.state_ph: img[None]})\n",
    "    print(_action)\n",
    "    obs,rew,done,info=env.step(_action)\n",
    "    img=env.render(mode='rgb_array')\n",
    "    time.sleep(0.1)\n",
    "    cv2.imwrite(env_to_use+'Test/img/'+str(i)+'.jpg',img)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "rws=np.array(log_rewards)\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.plot(rws[:,0],rws[:,1])\n",
    "plt.title('epoch vs sum of reward')\n",
    "plt.savefig(env_to_use+'Test/'+'rewards.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(rws[:,1],columns=['sum_of_rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(env_to_use+'Test/rewards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
