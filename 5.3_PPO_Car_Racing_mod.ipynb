{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow-gpu\n",
    "#pip install gym\n",
    "#pip install box2d\n",
    "#pip install pandas\n",
    "#pip install matplotlib\n",
    "#pip install opencv-python\n",
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense ,Input,concatenate ,Conv2D,Convolution2D,Conv2DTranspose,\\\n",
    "MaxPooling2D,AveragePooling2D, LSTM ,Reshape, TimeDistributed,ReLU, LeakyReLU, Dropout, BatchNormalization, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam,Adagrad\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import warnings\n",
    "import glob\n",
    "import math\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import deque\n",
    "from tqdm import tqdm,trange\n",
    "import gym\n",
    "from copy import copy , deepcopy\n",
    "import cProfile\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "TanH=tensorflow.keras.layers.Activation('tanh')\n",
    "Sigmoid=tensorflow.keras.layers.Activation('sigmoid')\n",
    "#tf.test.is_gpu_available()\n",
    "#tf.keras.backend.set_floatx('float64')\n",
    "physical_devices=tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steering_speed_gyro_abs(_img):\n",
    "    right_steering = _img[6, 36:46].mean()/255\n",
    "    left_steering = _img[6, 26:36].mean()/255\n",
    "    _steering = (right_steering - left_steering + 1.0)/2\n",
    "    \n",
    "    l_gyro = _img[6, 46:60].mean()/255\n",
    "    r_gyro = _img[6, 60:76].mean()/255\n",
    "    _gyro = (r_gyro - l_gyro + 1.0)/2\n",
    "    \n",
    "    \n",
    "    _speed =_img[:, 0][:-2].mean()/255\n",
    "    _abs1 = _img[:, 6][:-2].mean()/255\n",
    "    _abs2 = _img[:, 8][:-2].mean()/255\n",
    "    _abs3 = _img[:, 10][:-2].mean()/255\n",
    "    _abs4 = _img[:, 12][:-2].mean()/255\n",
    "    \n",
    "    return [_steering, _speed, _gyro, _abs1, _abs2, _abs3, _abs4]\n",
    "def get_states(img):\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY).reshape((img.shape[0],img.shape[1],1))\n",
    "    sensor_values=compute_steering_speed_gyro_abs(img)\n",
    "    img=np.array(img[:84,6:-6,:]/255.0,dtype=np.float32)\n",
    "    return img,sensor_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def Actor(n_act,N=8):\n",
    "    state_1=Input(shape=[84,84,1])\n",
    "    state_2=Input(shape=[7])\n",
    "    x = Conv2D(N,strides=2,kernel_size=7,activation='relu')(state_1)\n",
    "    x = Conv2D(2*N,strides=2,kernel_size=5,activation='relu')(x)\n",
    "    x = Conv2D(4*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Conv2D(8*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Conv2D(16*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    #x = Conv2D(32*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x,state_2])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    #x = Dense(256, activation='relu')(x)\n",
    "    mean = Dense(n_act)(x)\n",
    "    mean  = TanH(mean)\n",
    "    std = Dense(n_act)(x)\n",
    "    std  = Sigmoid(std)#+10e-10\n",
    "    actor_model=Model(inputs=[state_1,state_2],outputs=[mean,std])\n",
    "    return actor_model\n",
    "    \n",
    "def Critic(N=8):\n",
    "    state_1=Input(shape=[84,84,1])\n",
    "    state_2=Input(shape=[7])\n",
    "    x = Conv2D(N,strides=2,kernel_size=7,activation='relu')(state_1)\n",
    "    x = Conv2D(2*N,strides=2,kernel_size=5,activation='relu')(x)\n",
    "    x = Conv2D(4*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Conv2D(8*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Conv2D(16*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    #x = Conv2D(32*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x,state_2])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    #x = Dense(128, activation='relu')(x)\n",
    "    value = Dense(1)(x)\n",
    "    critic_model=Model(inputs=[state_1,state_2],outputs=[value])\n",
    "    return critic_model\n",
    "\n",
    "class ppo_model():\n",
    "    def __init__(self):\n",
    "        self._actor=Actor(n_act)\n",
    "        self._critic=Critic()\n",
    "        self._debug = False\n",
    "        self._actor_opt= Adam(0.001)\n",
    "        self._critic_opt= Adam(0.001)\n",
    "        self.value_coef=0.5\n",
    "        self.entropy_coef=0.01\n",
    "        self._gamma=0.99\n",
    "        self._lambda=0.95\n",
    "        self.clip_epsilon=0.1#0.05\n",
    "        self._advantage=16\n",
    "        \n",
    "    def get_advantages(self,values, masks, rewards):\n",
    "        target_qvals = []\n",
    "        for i in range(len(rewards)-self._advantage):\n",
    "            _values=values[i:i+self._advantage+1]\n",
    "            _rewards=rewards[i:i+self._advantage]\n",
    "            _masks=masks[i:i+self._advantage]\n",
    "            gae = 0\n",
    "            for j in reversed(range(self._advantage)):\n",
    "                delta = _rewards[j] + self._gamma * _values[j + 1] * _masks[j] - _values[j]\n",
    "                gae = delta + self._gamma * self._lambda * _masks[j] * gae\n",
    "            target_qvals.append(gae + _values[0])\n",
    "        target_qvals = np.array(target_qvals)\n",
    "        adv = np.array(target_qvals) - values[:-self._advantage-1]\n",
    "        return target_qvals, (adv - np.mean(adv)) / (np.std(adv) + 1e-10)\n",
    "    \n",
    "    def _get_advantages(self,values, masks, rewards):\n",
    "        target_qvals = []\n",
    "        gae=0\n",
    "        for i in reversed(range(len(rewards))):\n",
    "                delta = rewards[j] + self.gamma * values[j + 1] * masks[j] - values[j]\n",
    "                gae = delta + self._gamma * self._lambda * masks[j] * gae\n",
    "        target_qvals.append(gae + _values[0])\n",
    "        target_qvals = np.array(target_qvals)\n",
    "        adv = np.array(target_qvals) - values[:-self._advantage-1]\n",
    "        return target_qvals, (adv - np.mean(adv)) / (np.std(adv) + 1e-10)\n",
    "    \n",
    "    def actor_loss(self,mean,std,old_mean,old_std,old_action,advantage_raw):#, rewards, values):\n",
    "            old_probs = self.get_log_probs(old_action,old_mean,old_std)\n",
    "            new_probs = self.get_log_probs(old_action,mean,std)\n",
    "            entropy_loss = self.get_entropy(std)\n",
    "            ratio = K.exp(new_probs-old_probs)\n",
    "            p1 = ratio * advantage_raw\n",
    "            p2 = K.clip(ratio, min_value=1 - self.clip_epsilon, max_value=1 + self.clip_epsilon) * advantage_raw\n",
    "            actor_loss = K.mean(K.minimum(p1, p2))\n",
    "            #critic_loss = 0#K.mean(K.square(rewards - values))\n",
    "            total_loss =   -actor_loss - self.entropy_coef * entropy_loss #* K.mean(-(new_probs * K.log(new_probs + 1e-10)))\n",
    "            #tf.print('A',tf.reduce_sum(new_probs),tf.reduce_sum(old_probs),'B',tf.reduce_sum(ratio))\n",
    "            return total_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_actor(self,curr_states,_old_mean,_old_std,_old_actions,_advantage_raw):\n",
    "             _advantage_raw=tf.cast(_advantage_raw,tf.float32)\n",
    "             with tf.GradientTape() as tape:\n",
    "                  mean,std = self._actor(curr_states, training=True)\n",
    "                  if self._debug ==True :tf.print('1 : train_actor :',tf.reduce_sum(curr_states),tf.reduce_sum(mean),tf.reduce_sum(std))\n",
    "                  _act_loss = self.actor_loss(mean,std,_old_mean,_old_std,_old_actions,_advantage_raw)\n",
    "                  gradients = tape.gradient(_act_loss, self._actor.trainable_variables)\n",
    "                  self._actor_opt.apply_gradients(zip(gradients, self._actor.trainable_variables))\n",
    "                  #tf.print('actor grad : ',gradients[0])\n",
    "             return  _act_loss\n",
    "\n",
    "    @tf.function          \n",
    "    def critic_loss(self,_values,_target_rewards):\n",
    "            batch_size=_values.shape[0]\n",
    "            critic_loss=self.value_coef*2*tf.reduce_sum(tf.square(_target_rewards-_values))/batch_size\n",
    "            return critic_loss\n",
    "        \n",
    "    @tf.function\n",
    "    def train_critic(self,_states,_target_rewards):\n",
    "            with tf.GradientTape() as tape:\n",
    "                _values=self._critic(_states)\n",
    "                _values=tf.cast(_values,tf.float32)\n",
    "                _target_rewards=tf.cast(_target_rewards,tf.float32)\n",
    "                _critic_loss=self.critic_loss(_values,_target_rewards)\n",
    "                gradients = tape.gradient(_critic_loss, self._critic.trainable_variables)\n",
    "                self._critic_opt.apply_gradients(zip(gradients, self._critic.trainable_variables))\n",
    "                #tf.print('critic grad : ',gradients[0])\n",
    "            return _critic_loss\n",
    "    @tf.function\n",
    "    def get_log_probs(self,_actions,mean,std):\n",
    "        _actions=tf.cast(_actions,tf.float32)\n",
    "        mean=tf.cast(mean,tf.float32)\n",
    "        std=tf.cast(std,tf.float32)\n",
    "        _var = -0.5*((_actions-mean)/(std))**2\n",
    "        _coef = 1/(std*tf.sqrt(2*np.pi)) \n",
    "        \n",
    "        _probs = _coef*tf.cast(tf.exp(_var),tf.float32)\n",
    "        #_probs = tf.abs(_probs+ )\n",
    "        log_probs = tf.math.log(_probs)\n",
    "        #if _debug==True:\n",
    "        #    tf.print('2 : log_prob : _var  ',tf.reduce_sum(_var),tf.reduce_sum(_coef),tf.reduce_sum(_actions))\n",
    "        #    tf.print('2 : log_prob : _probs',tf.reduce_sum(_probs),tf.reduce_sum(log_probs))\n",
    "        return log_probs\n",
    "    def get_entropy(self,std):\n",
    "        entropy = 0.5 * (tf.math.log(2 * np.pi * std ** 2) + 1)\n",
    "        return entropy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_reward():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = get_states(state)\n",
    "        st_1=K.expand_dims(state[0], 0)\n",
    "        st_2=K.expand_dims(state[1], 0)\n",
    "        mean,std = _model._actor([st_1,st_2])\n",
    "        act=np.random.normal(mean,std)[0]\n",
    "        next_state, reward, done, _ = env.step(np.clip(mean[0],-1,1))\n",
    "        #if reward == -100:\n",
    "        #    reward=-2\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "    return total_reward\n",
    "    \n",
    "image_based = False\n",
    "\n",
    "env=gym.make('CarRacing-v0')\n",
    "env.seed(seed)\n",
    "\n",
    "\n",
    "n_state = env.observation_space.shape[0]\n",
    "n_act = env.action_space.shape[0]\n",
    "\n",
    "_model=ppo_model()\n",
    "ppo_steps = 2048\n",
    "train_epochs = 16\n",
    "batch_size = 128\n",
    "target_reached = False\n",
    "best_reward = 0\n",
    "iters = 0\n",
    "episodes = 1000\n",
    "adv=_model._advantage\n",
    "rewards_log=[]\n",
    "max_reward=0\n",
    "\n",
    "if not os.path.exists('replay_buffer_ppo'):\n",
    "       os.mkdir('replay_buffer_ppo') \n",
    "for episode in range(episodes):\n",
    "\n",
    "    \n",
    "    old_actions = []\n",
    "    old_probs =[]\n",
    "    values = []\n",
    "    masks = []\n",
    "    rewards = []\n",
    "    old_means = []\n",
    "    old_stds  = []\n",
    "    state_input = None\n",
    "    sum_reward=0\n",
    "    sum_reward_log=0\n",
    "    state = env.reset()\n",
    "    state=get_states(state)\n",
    "    for itr in trange(ppo_steps+adv):\n",
    "        st_1 = K.expand_dims(state[0], 0)\n",
    "        st_2 = K.expand_dims(state[1], 0)\n",
    "        mean,std = _model._actor([st_1,st_2])\n",
    "        q_value  = _model._critic([st_1,st_2])\n",
    "        action = np.random.normal(mean,std)[0]\n",
    "        #prob=get_log_probs(action,mean,std)\n",
    "        observation, reward, done, info = env.step(np.clip(action,-1,1))\n",
    "        state=get_states(observation)\n",
    "        #if reward == -100:\n",
    "        #    reward=-2\n",
    "        #print('itr: ' + str(itr) + ', action=' + str(action) + ', reward=' + str(reward) + ', q val=' + str(q_value.numpy()))\n",
    "        mask = not done\n",
    "        with open('replay_buffer_ppo/'+str(itr)+'.pkl','wb') as file:\n",
    "                      pickle.dump(state,file)\n",
    "        #_curr_states_1.append(state[0])\n",
    "        #_curr_states_2.append(state[1])\n",
    "        old_actions.append(action)\n",
    "        #old_probs.append(prob)\n",
    "        old_means.append(mean)\n",
    "        old_stds.append(std)\n",
    "        values.append(q_value)\n",
    "        masks.append(mask)\n",
    "        rewards.append(np.clip(reward,-.01,1000))\n",
    "        sum_reward+=reward\n",
    "\n",
    "        state = get_states(observation)\n",
    "        if done:\n",
    "            sum_reward_log=copy(sum_reward)\n",
    "            sum_reward=0\n",
    "            state=env.reset()\n",
    "            state = get_states(state)\n",
    "        \n",
    "    st_1=K.expand_dims(state[0], 0)\n",
    "    st_2=K.expand_dims(state[1], 0)\n",
    "    q_value = _model._critic([st_1,st_2])\n",
    "    values.append(q_value)\n",
    "    #_curr_states_1=np.array(_curr_states_1)#.reshape(-1,n_state)\n",
    "    #_curr_states_2=np.array(_curr_states_2)#.reshape(-1,n_state)\n",
    "    _old_actions=np.array(old_actions).reshape(-1,n_act)\n",
    "    _old_means=np.array(old_means).reshape(-1,n_act)\n",
    "    _old_stds=np.array(old_stds).reshape(-1,n_act)\n",
    "    _values=np.array(values).reshape(-1,1)\n",
    "    _rewards=np.array(rewards).reshape(-1,1)\n",
    "    _masks  = np.array(masks).reshape(-1,1)\n",
    "    \n",
    "    _target_qvals, _advantages = _model.get_advantages(_values, _masks, _rewards)\n",
    "    for _ in range(train_epochs):\n",
    "        no_of_batch=(ppo_steps//batch_size)\n",
    "        index=np.arange(ppo_steps)\n",
    "        np.random.shuffle(index)\n",
    "        for batch in range(no_of_batch):\n",
    "            _ind=index[batch*batch_size:(batch+1)*batch_size]\n",
    "            \n",
    "            _curr_states_1 = []\n",
    "            _curr_states_2 = []\n",
    "            for __ind in _ind:\n",
    "                with open('replay_buffer_ppo/'+str(__ind)+'.pkl','rb') as file:\n",
    "                    state= pickle.load(file)\n",
    "                    _curr_states_1.append(state[0])\n",
    "                    _curr_states_2.append(state[1])\n",
    "            _curr_states_1=np.array(_curr_states_1)\n",
    "            _curr_states_2=np.array(_curr_states_2)\n",
    "            \n",
    "            _model.train_actor([_curr_states_1,_curr_states_2],_old_means[_ind],_old_stds[_ind],_old_actions[_ind],_advantages[_ind])\n",
    "            _model.train_critic([_curr_states_1,_curr_states_2],_target_qvals[_ind])                            \n",
    "    #del _curr_states_1,_curr_states_2\n",
    "    avg_reward=0\n",
    "    for _ in range(5):\n",
    "        avg_reward += test_reward()\n",
    "    avg_reward/=5\n",
    "    print('episode :',episode,'reward :',sum_reward_log)   \n",
    "    print('total test reward=' + str(avg_reward))\n",
    "    if avg_reward >=max_reward:\n",
    "        _model._actor.save_weights('ppo_best_actor_car.hdf5')\n",
    "        _model._critic.save_weights('ppo_best_critic_car'+'.hdf5')\n",
    "        best_eps=episode\n",
    "        max_reward = avg_reward\n",
    "    rewards_log.append([sum_reward_log,avg_reward])\n",
    "    iters += 1\n",
    "    \n",
    "\n",
    "env.close()\n",
    "plt.plot(rewards_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f8fe72248>,\n",
       " <matplotlib.lines.Line2D at 0x20f9622ea88>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999.8000000000031"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_reward_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reward():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = get_states(state)\n",
    "        st_1=K.expand_dims(state[0], 0)\n",
    "        st_2=K.expand_dims(state[1], 0)\n",
    "        mean,std = _model._actor([st_1,st_2])\n",
    "        act=np.random.normal(mean,std)[0]\n",
    "        print(mean,std,act)\n",
    "        next_state, reward, done, _ = env.step(mean[0])\n",
    "        if reward == -100:\n",
    "            reward=-2\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "    return total_reward\n",
    "test_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_model._actor.save_weights('ppo-1000.hdf5')\n",
    "import pickle\n",
    "f=open('ppo-car-loss.pkl','wb')\n",
    "pickle.dump(rewards_log,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_model._actor.load_weights('ppo-1000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(old_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(_old_means)\n",
    "plt.show()\n",
    "plt.plot(_old_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards_log)\n",
    "plt.savefig('car-ppo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "seed=1\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense ,Input,concatenate ,Conv2D,Convolution2D,Conv2DTranspose,\\\n",
    "MaxPooling2D,AveragePooling2D, LSTM ,Reshape, TimeDistributed,ReLU, LeakyReLU, Dropout, BatchNormalization, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam,Adagrad\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import warnings\n",
    "import glob\n",
    "import math\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import deque\n",
    "from tqdm import tqdm,trange\n",
    "import gym\n",
    "from copy import copy , deepcopy\n",
    "import cProfile\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "TanH=tensorflow.keras.layers.Activation('tanh')\n",
    "Sigmoid=tensorflow.keras.layers.Activation('sigmoid')\n",
    "#tf.test.is_gpu_available()\n",
    "#tf.keras.backend.set_floatx('float64')\n",
    "physical_devices=tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "try:os.mkdir('car_ppo')\n",
    "except:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1055..1332 -> 277-tiles track\n"
     ]
    }
   ],
   "source": [
    "def Actor(n_act,N=8):\n",
    "    state_1=Input(shape=[84,84,1])\n",
    "    state_2=Input(shape=[7])\n",
    "    x = Conv2D(N,strides=2,kernel_size=7,activation='relu')(state_1)\n",
    "    x = Conv2D(2*N,strides=2,kernel_size=5,activation='relu')(x)\n",
    "    x = Conv2D(4*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Conv2D(8*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Conv2D(16*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    #x = Conv2D(32*N,strides=2,kernel_size=3,activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x,state_2])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    #x = Dense(256, activation='relu')(x)\n",
    "    mean = Dense(n_act)(x)\n",
    "    mean  = TanH(mean)\n",
    "    std = Dense(n_act)(x)\n",
    "    std  = Sigmoid(std)#+10e-10\n",
    "    actor_model=Model(inputs=[state_1,state_2],outputs=[mean,std])\n",
    "    return actor_model\n",
    "    \n",
    "def compute_steering_speed_gyro_abs(_img):\n",
    "    right_steering = _img[6, 36:46].mean()/255\n",
    "    left_steering = _img[6, 26:36].mean()/255\n",
    "    _steering = (right_steering - left_steering + 1.0)/2\n",
    "    \n",
    "    l_gyro = _img[6, 46:60].mean()/255\n",
    "    r_gyro = _img[6, 60:76].mean()/255\n",
    "    _gyro = (r_gyro - l_gyro + 1.0)/2\n",
    "    \n",
    "    \n",
    "    _speed =_img[:, 0][:-2].mean()/255\n",
    "    _abs1 = _img[:, 6][:-2].mean()/255\n",
    "    _abs2 = _img[:, 8][:-2].mean()/255\n",
    "    _abs3 = _img[:, 10][:-2].mean()/255\n",
    "    _abs4 = _img[:, 12][:-2].mean()/255\n",
    "    \n",
    "    return [_steering, _speed, _gyro, _abs1, _abs2, _abs3, _abs4]\n",
    "def get_states(img):\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY).reshape((img.shape[0],img.shape[1],1))\n",
    "    sensor_values=compute_steering_speed_gyro_abs(img)\n",
    "    img=np.array(img[:84,6:-6,:]/255.0,dtype=np.float32)\n",
    "    return img,sensor_values\n",
    "\n",
    "env = gym.make('CarRacing-v0')\n",
    "env.seed(seed)\n",
    "n_act=env.action_space.shape[0]\n",
    "n_state=env.observation_space.shape[0]\n",
    "state=env.reset()\n",
    "_actor=Actor(n_act)\n",
    "_state=get_states(state)\n",
    "st_1 = K.expand_dims(_state[0], 0)\n",
    "st_2 = K.expand_dims(_state[1], 0)\n",
    "_actor([st_1,st_2])\n",
    "_actor.load_weights('ppo_best_actor_car.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_states(state)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03056718,         nan, -0.36565146], dtype=float32),\n",
       " -0.10000000000002274,\n",
       " True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_state,rwd,ter,info=env.step(action)\n",
    "action,rwd,ter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1172..1469 -> 297-tiles track\n",
      "Track generation: 1136..1424 -> 288-tiles track\n",
      "Track generation: 1060..1329 -> 269-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-105a368e6ffe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0m_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"state_pixels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mstep_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglViewport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVP_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVP_H\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_road\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[0mgeom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mrender_road\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglVertex3f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroad_poly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglColor4f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m                 \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglVertex3f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\pyglet\\gl\\lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[1;34m(result, func, arguments)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_state=env.reset()\n",
    "state=get_states(_state)\n",
    "i=0\n",
    "ter_count=0\n",
    "while True:\n",
    "    st_1 = K.expand_dims(state[0], 0)\n",
    "    st_2 = K.expand_dims(state[1], 0)\n",
    "    mean,std=_actor([st_1,st_2])\n",
    "    action=np.clip(mean[0],-1,1)\n",
    "    action=np.nan_to_num(action)\n",
    "    _state,rwd,ter,info=env.step(action)\n",
    "    state=get_states(_state)\n",
    "    img=env.render('rgb_array')\n",
    "    cv2.imwrite('car_ppo/'+str(i)+'.jpg',img)\n",
    "    i+=1\n",
    "    if ter==True:\n",
    "            ter_count+=1\n",
    "            _state=env.reset()\n",
    "            state=get_states(_state)\n",
    "    if ter_count==5:\n",
    "             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
